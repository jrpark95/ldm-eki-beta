================================================================================
LDM-EKI 시각화 및 후처리 도구 보고서 - Part 1
================================================================================

작성일: 2025-10-18
대상 시스템: LDM-EKI v1.0 (Lagrangian Dispersion Model with Ensemble Kalman Inversion)
문서 범위: cleanup.py, compare_all_receptors.py 완전 분석
작성자: 에이전트 #4 (시각화 및 후처리 도구 전문가)

================================================================================
목차 - Part 1
================================================================================

1. 개요 .............................................................. 150줄
   1.1 후처리 도구의 목적과 중요성
   1.2 도구 분류 및 역할
   1.3 워크플로우 다이어그램
   1.4 파일 구조 및 의존성

2. cleanup.py 완전 분석 .............................................. 400줄
   2.1 스크립트 개요
   2.2 전체 코드 구조
   2.3 주요 함수 분석
   2.4 사용 예제 및 옵션
   2.5 안전장치 메커니즘

3. compare_all_receptors.py 완전 분석 ................................ 450줄
   3.1 스크립트 개요
   3.2 전체 코드 구조
   3.3 주요 함수 분석
   3.4 플롯 생성 로직
   3.5 사용 예제 및 출력물

================================================================================
1. 개요
================================================================================

1.1 후처리 도구의 목적과 중요성
================================================================================

LDM-EKI 시스템은 2-프로세스 아키텍처(C++/CUDA 순방향 모델 + Python 역산 모델)로
구성되어 있으며, 시뮬레이션 실행 중 대량의 데이터를 생성합니다:

- 로그 파일 (logs/): 시뮬레이션 진행 상황, 에러, 관측값
- VTK 파일 (output/plot_vtk_*/): 입자 분포 시각화 데이터
- 공유 메모리 (dev/shm/ldm_eki_*): IPC 통신 버퍼
- 디버그 데이터 (logs/debug/): NPZ 아카이브 형태의 상세 로그
- 그래프 (output/results/): PNG 형식의 최종 시각화

이러한 데이터를 효과적으로 관리, 정리, 분석, 시각화하기 위해 4개의 Python 유틸리티가
개발되었습니다. 이 도구들은 다음과 같은 핵심 역할을 수행합니다:

1. **데이터 정리 (cleanup.py)**
   - 이전 실행 데이터 안전 삭제
   - 디스크 공간 회수
   - 공유 메모리 누수 방지

2. **실시간 결과 시각화 (compare_all_receptors.py)**
   - 수용체별 관측 비교
   - 앙상블 통계 표시
   - 방출량 추정 그래프
   - 시뮬레이션 종료 시 자동 실행

3. **상세 후처리 (detailed_postprocess.py)**
   - NPZ 디버그 데이터 추출
   - 통계 분석 및 개별 플롯
   - 설정 요약 생성
   - 선택적 수동 실행

4. **VTK 시각화 (visualize_vtk.py)**
   - 입자 분포 히트맵
   - 지리적 지도 오버레이
   - GIF 애니메이션 생성
   - 선택적 수동 실행

1.2 도구 분류 및 역할
================================================================================

도구 분류:

┌─────────────────────────────────────────────────────────────────────┐
│                        LDM-EKI 후처리 도구                          │
├─────────────────────────────────────────────────────────────────────┤
│                                                                       │
│  [필수 도구 - 자동 실행]                                            │
│  ┌───────────────────────────────────────────────────────────┐      │
│  │ cleanup.py (데이터 정리)                                  │      │
│  │  - 실행 시점: ldm-eki 시작 시 (사용자 확인 후)           │      │
│  │  - 목적: 이전 데이터 삭제, 공유 메모리 정리               │      │
│  │  - 출력: 터미널 메시지, 통계                              │      │
│  └───────────────────────────────────────────────────────────┘      │
│                                                                       │
│  ┌───────────────────────────────────────────────────────────┐      │
│  │ compare_all_receptors.py (결과 시각화)                    │      │
│  │  - 실행 시점: ldm-eki 종료 시 (자동)                      │      │
│  │  - 목적: 수용체별 비교, 방출량 추정 플롯                  │      │
│  │  - 출력: output/results/all_receptors_comparison*.png     │      │
│  └───────────────────────────────────────────────────────────┘      │
│                                                                       │
│  [선택 도구 - 수동 실행]                                            │
│  ┌───────────────────────────────────────────────────────────┐      │
│  │ detailed_postprocess.py (상세 분석)                       │      │
│  │  - 실행 시점: 필요 시 수동                                │      │
│  │  - 목적: NPZ 데이터 추출, 통계, 개별 플롯                 │      │
│  │  - 출력: logs/debug/extracted_data.txt, 개별 PNG          │      │
│  └───────────────────────────────────────────────────────────┘      │
│                                                                       │
│  ┌───────────────────────────────────────────────────────────┐      │
│  │ visualize_vtk.py (입자 분포 시각화)                       │      │
│  │  - 실행 시점: 필요 시 수동                                │      │
│  │  - 목적: 지리적 히트맵, GIF 애니메이션                    │      │
│  │  - 출력: output/results/particle_distribution_*.gif       │      │
│  └───────────────────────────────────────────────────────────┘      │
│                                                                       │
└─────────────────────────────────────────────────────────────────────┘

1.3 워크플로우 다이어그램
================================================================================

전체 시뮬레이션 워크플로우에서 후처리 도구의 위치:

[사용자 실행 명령]
    │
    └─> ./ldm-eki
         │
         ├─> [1단계] cleanup.py 호출
         │    │
         │    ├─ 사용자 확인 프롬프트
         │    ├─ logs/ 디렉토리 정리
         │    ├─ output/ 디렉토리 정리
         │    ├─ /dev/shm/ldm_eki_* 정리
         │    └─ 통계 출력
         │
         ├─> [2단계] LDM-EKI 시뮬레이션 실행
         │    │
         │    ├─ 초기 참값 시뮬레이션 (SINGLE 모드)
         │    │   └─> VTK 출력: output/plot_vtk_prior/*.vtk
         │    │
         │    ├─ Python EKI 프로세스 시작
         │    │   └─> 디버그 로깅: logs/debug/eki_debug_data.npz
         │    │
         │    ├─ EKI 반복 (N회)
         │    │   ├─ 앙상블 시뮬레이션 (ENSEMBLE 모드)
         │    │   ├─ 공유 메모리 IPC 통신
         │    │   └─ 수렴 체크
         │    │
         │    └─ 최종 VTK 출력: output/plot_vtk_ens/*.vtk
         │
         └─> [3단계] compare_all_receptors.py 자동 호출
              │
              ├─ 로그 파싱 (ldm_eki_simulation.log)
              ├─ 공유 메모리 읽기 (ensemble observations)
              ├─ 플롯 생성 (16개 수용체 x 다중 페이지)
              └─ 저장: output/results/all_receptors_comparison*.png

[선택적 수동 실행]
    │
    ├─> python3 util/detailed_postprocess.py
    │    │
    │    ├─ NPZ 데이터 추출 → logs/debug/extracted_data.txt
    │    ├─ 개별 플롯 생성 → output/results/receptor_*.png
    │    └─ 설정 요약 → output/results/config_summary.md
    │
    └─> python3 util/visualize_vtk.py
         │
         ├─ VTK 파일 읽기 (PyVista)
         ├─ 히트맵 생성 (Cartopy 지도)
         └─ GIF 애니메이션 → output/results/particle_distribution.gif

1.4 파일 구조 및 의존성
================================================================================

디렉토리 레이아웃:

ldm-eki-release.v.beta/
│
├── util/                       # 후처리 유틸리티 스크립트
│   ├── cleanup.py              # 데이터 정리 (319줄)
│   ├── compare_all_receptors.py # 결과 시각화 (587줄)
│   ├── detailed_postprocess.py  # 상세 분석 (약 600줄)
│   └── visualize_vtk.py         # VTK 시각화 (약 700줄)
│
├── input/                      # 설정 파일
│   ├── receptor.conf           # 수용체 위치 정의
│   ├── eki.conf                # EKI 알고리즘 파라미터
│   └── setting.txt             # LDM 시뮬레이션 설정
│
├── logs/                       # 로그 파일 (cleanup.py로 정리)
│   ├── ldm_eki_simulation.log  # 메인 시뮬레이션 로그
│   ├── python_eki_output.log   # Python EKI 프로세스 로그
│   ├── debug/                  # 디버그 데이터
│   │   └── eki_debug_data.npz  # NPZ 아카이브
│   └── error/                  # 커널 에러 로그
│
├── output/                     # 출력 파일 (cleanup.py로 정리)
│   ├── plot_vtk_prior/         # 참값 시뮬레이션 VTK
│   ├── plot_vtk_ens/           # 앙상블 시뮬레이션 VTK
│   └── results/                # 그래프 및 분석 결과
│       ├── all_receptors_comparison_page*.png
│       ├── particle_distribution.gif
│       └── config_summary.md
│
└── /dev/shm/                   # 공유 메모리 (cleanup.py로 정리)
    ├── ldm_eki_data            # 초기 관측 데이터
    ├── ldm_eki_ensemble_*      # 앙상블 상태/관측
    └── ldm_eki_full_config     # 전체 설정

의존성 맵:

cleanup.py:
    - Python 표준 라이브러리: os, sys, glob, shutil, argparse, pathlib
    - 외부 의존성: 없음
    - 읽기: /dev/shm/ldm_eki_*
    - 쓰기: logs/, output/ (삭제 작업)

compare_all_receptors.py:
    - Python 라이브러리: numpy, matplotlib, struct, re, os
    - 읽기:
        - input/receptor.conf
        - input/eki.conf
        - logs/ldm_eki_simulation.log
        - /dev/shm/ldm_eki_ensemble_obs_*
        - logs/eki_iterations/*.npy
    - 쓰기:
        - output/results/all_receptors_comparison*.png

detailed_postprocess.py (Part 2에서 다룰 예정):
    - Python 라이브러리: numpy, matplotlib, os
    - 읽기: logs/debug/eki_debug_data.npz, input/*.conf
    - 쓰기: output/results/*, logs/debug/extracted_data.txt

visualize_vtk.py (Part 2에서 다룰 예정):
    - Python 라이브러리: pyvista, cartopy, matplotlib, scipy, imageio
    - 읽기: output/plot_vtk_*/*.vtk
    - 쓰기: output/results/particle_distribution*.gif

================================================================================
2. cleanup.py 완전 분석
================================================================================

2.1 스크립트 개요
================================================================================

파일 경로: /home/jrpark/ldm-eki-release.v.beta/util/cleanup.py
총 줄 수: 319줄
목적: LDM-EKI 시뮬레이션 이전 데이터 안전 삭제
실행 시점: ldm-eki 시작 시 자동 호출 (사용자 확인 후)
언어: Python 3
외부 의존성: 없음 (표준 라이브러리만 사용)

주요 기능:
1. logs/ 디렉토리 내용 정리
2. output/ 디렉토리 내용 정리
3. /dev/shm/ldm_eki_* 공유 메모리 파일 정리
4. 디렉토리 크기 및 파일 개수 계산
5. 사용자 확인 프롬프트
6. Dry-run 모드 지원
7. 통계 출력 (삭제된 파일 수, 회수된 공간)

안전장치:
- 기본적으로 확인 프롬프트 표시 (--no-confirm으로 비활성화 가능)
- Dry-run 모드로 미리보기 가능
- 디렉토리 자체는 삭제하지 않고 내용만 삭제
- 권한 에러 처리 (PermissionError 예외 처리)
- 파일별 개별 에러 처리 (일부 실패 시에도 계속 진행)

2.2 전체 코드 구조
================================================================================

[1-20줄] Docstring 및 Import
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
#!/usr/bin/env python3
"""
LDM-EKI Cleanup Script

Safely removes temporary data and shared memory files:
- ./logs/ directory contents
- ./output/ directory contents
- /dev/shm/ldm_eki_* shared memory files

Usage:
    python3 util/cleanup.py [options]

Options:
    --dry-run    Show what would be deleted without actually deleting
    --no-confirm Skip confirmation prompt
    --logs-only  Only clean logs directory
    --output-only Only clean output directory
    --shm-only   Only clean shared memory
"""

import os
import sys
import glob
import shutil
import argparse
from pathlib import Path

[28-36줄] ANSI 색상 코드 정의
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# ANSI color codes
class Color:
    RESET = '\033[0m'
    RED = '\033[31m'
    GREEN = '\033[32m'
    YELLOW = '\033[33m'
    BLUE = '\033[34m'
    CYAN = '\033[36m'
    BOLD = '\033[1m'

목적: 터미널 출력에 색상 적용하여 가독성 향상
- GREEN: 성공 메시지 (✓ 체크마크)
- CYAN: 헤더 및 섹션 제목
- BOLD: 중요 정보 강조
- RESET: 색상 초기화

[38-41줄] 프로젝트 루트로 작업 디렉토리 변경
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Change to project root directory
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
os.chdir(project_root)

이유: util/ 폴더에서 실행되어도 항상 프로젝트 루트 기준으로 경로 처리

[43-53줄] 공유 메모리 파일 패턴 정의
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
# Known shared memory file patterns (from code analysis)
SHM_PATTERNS = [
    "/dev/shm/ldm_eki_*",
    "/dev/shm/ldm_eki_config",
    "/dev/shm/ldm_eki_data",
    "/dev/shm/ldm_eki_ensemble_config",
    "/dev/shm/ldm_eki_ensemble_data",
    "/dev/shm/ldm_eki_ensemble_obs_config",
    "/dev/shm/ldm_eki_ensemble_obs_data",
    "/dev/shm/ldm_eki_full_config",
]

설명:
- 첫 번째 패턴 "/dev/shm/ldm_eki_*"이 모든 파일을 캐치
- 나머지는 명시적으로 알려진 파일 이름들 (코드 분석 결과)
- 공유 메모리는 프로세스 종료 후에도 남아있어 수동 정리 필요

2.3 주요 함수 분석
================================================================================

함수 1: get_directory_size(path)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[55-66줄]

def get_directory_size(path):
    """Calculate total size of a directory in bytes"""
    total = 0
    try:
        for entry in os.scandir(path):
            if entry.is_file(follow_symlinks=False):
                total += entry.stat().st_size
            elif entry.is_dir(follow_symlinks=False):
                total += get_directory_size(entry.path)
    except (PermissionError, FileNotFoundError):
        pass
    return total

목적: 디렉토리의 전체 크기를 바이트 단위로 계산 (재귀적)
알고리즘:
    1. os.scandir()으로 디렉토리 스캔 (빠른 성능)
    2. 파일이면 크기 누적
    3. 서브디렉토리면 재귀 호출
    4. 심볼릭 링크는 무시 (follow_symlinks=False)
예외 처리:
    - PermissionError: 권한 없는 파일 무시
    - FileNotFoundError: 삭제된 파일 무시
반환값: int (총 바이트 수)

함수 2: format_size(bytes_size)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[68-74줄]

def format_size(bytes_size):
    """Format bytes to human-readable size"""
    for unit in ['B', 'KB', 'MB', 'GB']:
        if bytes_size < 1024.0:
            return f"{bytes_size:.2f} {unit}"
        bytes_size /= 1024.0
    return f"{bytes_size:.2f} TB"

목적: 바이트를 사람이 읽기 쉬운 형식으로 변환
예시:
    - 512 → "512.00 B"
    - 1536 → "1.50 KB"
    - 2097152 → "2.00 MB"
    - 5368709120 → "5.00 GB"
알고리즘: 1024씩 나누면서 적절한 단위 찾기

함수 3: scan_shared_memory()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[76-94줄]

def scan_shared_memory():
    """Scan for all LDM-EKI shared memory files"""
    shm_files = set()

    # Use glob patterns to find files
    for pattern in SHM_PATTERNS:
        matches = glob.glob(pattern)
        shm_files.update(matches)

    # Also scan /dev/shm directly for any ldm_eki files
    try:
        if os.path.exists('/dev/shm'):
            for entry in os.scandir('/dev/shm'):
                if entry.name.startswith('ldm_eki'):
                    shm_files.add(entry.path)
    except PermissionError:
        print("Warning: No permission to scan /dev/shm")

    return sorted(shm_files)

목적: 모든 LDM-EKI 공유 메모리 파일 찾기
알고리즘:
    1. glob 패턴으로 파일 검색
    2. set()으로 중복 제거
    3. /dev/shm 직접 스캔 (추가 안전장치)
    4. 정렬된 리스트 반환
반환값: 정렬된 파일 경로 리스트
예외 처리: /dev/shm 접근 권한 없을 때 경고 출력

함수 4: count_files_recursive(path)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[96-104줄]

def count_files_recursive(path):
    """Count files recursively in a directory"""
    count = 0
    try:
        for root, dirs, files in os.walk(path):
            count += len(files)
    except (PermissionError, FileNotFoundError):
        pass
    return count

목적: 디렉토리의 전체 파일 개수 계산 (재귀적)
알고리즘: os.walk()로 모든 서브디렉토리 순회
반환값: int (총 파일 수)
성능: 매우 빠름 (os.walk()는 C로 최적화됨)

함수 5: clean_directory(path, dry_run=False)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[106-149줄]

def clean_directory(path, dry_run=False):
    """Clean all contents of a directory while preserving the directory itself"""
    if not os.path.exists(path):
        print(f"  Directory does not exist: {path}")
        return 0, 0

    file_count = count_files_recursive(path)
    dir_size = get_directory_size(path)

    if file_count == 0:
        print(f"  ✓ Directory is already empty: {path}")
        return 0, 0

    if dry_run:
        print(f"  [DRY RUN] Would delete {file_count} files ({format_size(dir_size)}) from {path}")
        return file_count, dir_size

    # Delete contents
    removed_files = 0
    removed_size = 0

    try:
        for item in os.listdir(path):
            item_path = os.path.join(path, item)
            try:
                if os.path.isfile(item_path) or os.path.islink(item_path):
                    size = os.path.getsize(item_path)
                    os.unlink(item_path)
                    removed_files += 1
                    removed_size += size
                elif os.path.isdir(item_path):
                    size = get_directory_size(item_path)
                    shutil.rmtree(item_path)
                    removed_files += count_files_recursive(item_path)
                    removed_size += size
            except Exception as e:
                print(f"  Warning: Failed to delete {item_path}: {e}")

        print(f"  {Color.GREEN}✓{Color.RESET} Cleaned {path}: {Color.BOLD}{removed_files}{Color.RESET} files ({format_size(removed_size)})")
    except Exception as e:
        print(f"  Error cleaning {path}: {e}")
        return 0, 0

    return removed_files, removed_size

목적: 디렉토리 내용 삭제 (디렉토리 자체는 유지)
파라미터:
    - path: 정리할 디렉토리 경로
    - dry_run: True이면 미리보기만 (실제 삭제 안 함)
반환값: (삭제된 파일 수, 삭제된 바이트 수) 튜플

알고리즘:
    1. 디렉토리 존재 확인
    2. 파일 수/크기 계산
    3. Dry-run이면 미리보기만 출력
    4. 실제 삭제:
        - os.listdir()로 최상위 항목 나열
        - 파일/링크: os.unlink()
        - 디렉토리: shutil.rmtree() (재귀 삭제)
    5. 통계 반환

안전장치:
    - 디렉토리 자체는 삭제 안 함 (os.rmdir() 사용 안 함)
    - 개별 파일 실패 시 경고만 출력하고 계속 진행
    - 파일 크기는 삭제 전에 저장 (삭제 후 크기 읽기 불가)

주의사항:
    - 서브디렉토리의 파일 수는 count_files_recursive()로 계산
    - 이미 삭제된 디렉토리의 파일 수는 0이 됨 (버그 아님)
    - 실제로는 shutil.rmtree() 전에 크기를 미리 계산했으므로 정확함

함수 6: clean_shared_memory(dry_run=False)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[151-184줄]

def clean_shared_memory(dry_run=False):
    """Clean shared memory files"""
    shm_files = scan_shared_memory()

    if not shm_files:
        print(f"  {Color.GREEN}✓{Color.RESET} No shared memory files found")
        return 0, 0

    removed_count = 0
    removed_size = 0

    for shm_file in shm_files:
        try:
            size = os.path.getsize(shm_file)

            if dry_run:
                print(f"  [DRY RUN] Would delete: {shm_file} ({format_size(size)})")
            else:
                os.unlink(shm_file)
                print(f"  {Color.GREEN}✓{Color.RESET} Deleted: {shm_file} ({format_size(size)})")
                removed_count += 1
                removed_size += size
        except FileNotFoundError:
            # File already deleted
            pass
        except PermissionError:
            print(f"  Warning: Permission denied: {shm_file}")
        except Exception as e:
            print(f"  Warning: Failed to delete {shm_file}: {e}")

    if not dry_run and removed_count > 0:
        print(f"  {Color.GREEN}✓{Color.RESET} Cleaned {Color.BOLD}{removed_count}{Color.RESET} shared memory files ({format_size(removed_size)})")

    return removed_count, removed_size

목적: 공유 메모리 파일 정리
알고리즘:
    1. scan_shared_memory()로 파일 목록 가져오기
    2. 각 파일에 대해:
        - Dry-run이면 미리보기 출력
        - 아니면 os.unlink()로 삭제
    3. 통계 출력

예외 처리:
    - FileNotFoundError: 이미 삭제된 파일 (무시)
    - PermissionError: 권한 없음 (경고 출력)
    - 기타 예외: 경고 출력하고 계속 진행

왜 디렉토리와 다르게 처리?
    - 공유 메모리는 디렉토리 구조가 아님 (평평한 파일들)
    - 파일별로 개별 처리하여 더 상세한 피드백 제공

함수 7: main()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[186-308줄]

def main():
    parser = argparse.ArgumentParser(
        description='Clean LDM-EKI temporary data and shared memory files',
        formatter_class=argparse.RawDescriptionHelpFormatter
    )
    parser.add_argument('--dry-run', action='store_true',
                        help='Show what would be deleted without actually deleting')
    parser.add_argument('--no-confirm', action='store_true',
                        help='Skip confirmation prompt')
    parser.add_argument('--logs-only', action='store_true',
                        help='Only clean logs directory')
    parser.add_argument('--output-only', action='store_true',
                        help='Only clean output directory')
    parser.add_argument('--shm-only', action='store_true',
                        help='Only clean shared memory')

    args = parser.parse_args()

    # Determine what to clean
    clean_logs = args.logs_only or (not args.output_only and not args.shm_only)
    clean_output = args.output_only or (not args.logs_only and not args.shm_only)
    clean_shm = args.shm_only or (not args.logs_only and not args.output_only)

    print("=" * 70)
    print(f"{Color.CYAN}{Color.BOLD}LDM-EKI CLEANUP SCRIPT{Color.RESET}")
    print("=" * 70)
    print(f"Working directory: {Color.BOLD}{os.getcwd()}{Color.RESET}")

    if args.dry_run:
        print("\nDRY RUN MODE - No files will be deleted\n")

    # Show what will be cleaned
    print(f"\n{Color.BOLD}Items to be cleaned:{Color.RESET}")
    if clean_logs:
        print("  - ./logs/")
    if clean_output:
        print("  - ./output/")
    if clean_shm:
        print("  - /dev/shm/ldm_eki_* (shared memory)")

    # Scan and show preview
    print("\n" + "=" * 70)
    print(f"{Color.CYAN}SCANNING...{Color.RESET}")
    print("=" * 70)

    total_files = 0
    total_size = 0

    if clean_logs and os.path.exists('logs'):
        log_files = count_files_recursive('logs')
        log_size = get_directory_size('logs')
        print(f"logs/: {log_files} files, {format_size(log_size)}")
        total_files += log_files
        total_size += log_size

    if clean_output and os.path.exists('output'):
        output_files = count_files_recursive('output')
        output_size = get_directory_size('output')
        print(f"output/: {output_files} files, {format_size(output_size)}")
        total_files += output_files
        total_size += output_size

    if clean_shm:
        shm_files = scan_shared_memory()
        shm_size = sum(os.path.getsize(f) for f in shm_files if os.path.exists(f))
        print(f"shared memory: {len(shm_files)} files, {format_size(shm_size)}")
        total_files += len(shm_files)
        total_size += shm_size

    print(f"\n{Color.BOLD}Total: {total_files} files, {format_size(total_size)}{Color.RESET}")

    if total_files == 0:
        print(f"\n{Color.GREEN}✓{Color.RESET} Nothing to clean - all directories are already empty")
        return 0

    # Confirmation
    if not args.no_confirm and not args.dry_run:
        print("\n" + "=" * 70)
        response = input("Do you want to proceed? [y/N]: ").strip().lower()
        if response not in ['y', 'yes']:
            print("Aborted.")
            return 0

    # Perform cleanup
    print("\n" + "=" * 70)
    print(f"{Color.CYAN}CLEANING...{Color.RESET}")
    print("=" * 70)

    removed_files = 0
    removed_size = 0

    if clean_logs:
        print("\nCleaning logs/...")
        count, size = clean_directory('logs', args.dry_run)
        removed_files += count
        removed_size += size

    if clean_output:
        print("\nCleaning output/...")
        count, size = clean_directory('output', args.dry_run)
        removed_files += count
        removed_size += size

    if clean_shm:
        print("\nCleaning shared memory...")
        count, size = clean_shared_memory(args.dry_run)
        removed_files += count
        removed_size += size

    # Summary
    print("\n" + "=" * 70)
    print(f"{Color.CYAN}SUMMARY{Color.RESET}")
    print("=" * 70)

    if args.dry_run:
        print(f"Would delete: {removed_files} files ({format_size(removed_size)})")
        print("\nRun without --dry-run to actually delete files")
    else:
        print(f"Deleted: {removed_files} files ({format_size(removed_size)})")
        print(f"{Color.GREEN}✓{Color.RESET} Cleanup complete")

    print("=" * 70)
    return 0

목적: 메인 실행 로직 및 사용자 인터페이스
흐름:
    1. 명령줄 인자 파싱
    2. 정리 대상 결정 (논리 연산)
    3. 헤더 출력
    4. 스캔 단계 (미리보기)
    5. 확인 프롬프트
    6. 실제 정리
    7. 요약 출력

논리 연산 (204-207줄):
    clean_logs = args.logs_only or (not args.output_only and not args.shm_only)

    진리표:
        logs_only  output_only  shm_only  →  clean_logs  clean_output  clean_shm
        False      False        False         True        True          True      (전부 정리)
        True       False        False         True        False         False
        False      True         False         False       True          False
        False      False        True          False       False         True

    즉, 아무 옵션도 안 주면 전부 정리, 하나라도 주면 그것만 정리

확인 프롬프트 로직 (262-267줄):
    - dry_run이면 확인 안 함
    - no_confirm이면 확인 안 함
    - 둘 다 아니면 사용자에게 "Do you want to proceed? [y/N]:" 물어봄
    - y 또는 yes 아니면 중단

2.4 사용 예제 및 옵션
================================================================================

예제 1: 기본 실행 (모든 데이터 정리)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
$ python3 util/cleanup.py

출력:
======================================================================
LDM-EKI CLEANUP SCRIPT
======================================================================
Working directory: /home/jrpark/ldm-eki-release.v.beta

Items to be cleaned:
  - ./logs/
  - ./output/
  - /dev/shm/ldm_eki_* (shared memory)

======================================================================
SCANNING...
======================================================================
logs/: 3 files, 45.23 KB
output/: 234 files, 156.78 MB
shared memory: 8 files, 1.25 MB

Total: 245 files, 158.08 MB

======================================================================
Do you want to proceed? [y/N]: y

======================================================================
CLEANING...
======================================================================

Cleaning logs/...
  ✓ Cleaned logs/: 3 files (45.23 KB)

Cleaning output/...
  ✓ Cleaned output/: 234 files (156.78 MB)

Cleaning shared memory...
  ✓ Deleted: /dev/shm/ldm_eki_data (128.00 KB)
  ✓ Deleted: /dev/shm/ldm_eki_ensemble_config (4.00 B)
  ✓ Deleted: /dev/shm/ldm_eki_ensemble_data (1.12 MB)
  ...
  ✓ Cleaned 8 shared memory files (1.25 MB)

======================================================================
SUMMARY
======================================================================
Deleted: 245 files (158.08 MB)
✓ Cleanup complete
======================================================================

예제 2: Dry-run 모드 (미리보기)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
$ python3 util/cleanup.py --dry-run

출력:
======================================================================
LDM-EKI CLEANUP SCRIPT
======================================================================
Working directory: /home/jrpark/ldm-eki-release.v.beta

DRY RUN MODE - No files will be deleted

Items to be cleaned:
  - ./logs/
  - ./output/
  - /dev/shm/ldm_eki_* (shared memory)

======================================================================
SCANNING...
======================================================================
logs/: 3 files, 45.23 KB
output/: 234 files, 156.78 MB
shared memory: 8 files, 1.25 MB

Total: 245 files, 158.08 MB

======================================================================
CLEANING...
======================================================================

Cleaning logs/...
  [DRY RUN] Would delete 3 files (45.23 KB) from logs

Cleaning output/...
  [DRY RUN] Would delete 234 files (156.78 MB) from output

Cleaning shared memory...
  [DRY RUN] Would delete: /dev/shm/ldm_eki_data (128.00 KB)
  [DRY RUN] Would delete: /dev/shm/ldm_eki_ensemble_config (4.00 B)
  ...

======================================================================
SUMMARY
======================================================================
Would delete: 245 files (158.08 MB)

Run without --dry-run to actually delete files
======================================================================

주의: dry-run 모드에서는 확인 프롬프트가 나타나지 않음

예제 3: 로그만 정리
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
$ python3 util/cleanup.py --logs-only

출력:
======================================================================
LDM-EKI CLEANUP SCRIPT
======================================================================
Working directory: /home/jrpark/ldm-eki-release.v.beta

Items to be cleaned:
  - ./logs/

======================================================================
SCANNING...
======================================================================
logs/: 3 files, 45.23 KB

Total: 3 files, 45.23 KB

======================================================================
Do you want to proceed? [y/N]: y

======================================================================
CLEANING...
======================================================================

Cleaning logs/...
  ✓ Cleaned logs/: 3 files (45.23 KB)

======================================================================
SUMMARY
======================================================================
Deleted: 3 files (45.23 KB)
✓ Cleanup complete
======================================================================

예제 4: 확인 없이 즉시 실행
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
$ python3 util/cleanup.py --no-confirm

출력:
(확인 프롬프트 없이 바로 정리 시작)

사용 사례: 자동화 스크립트에서 호출할 때

예제 5: 공유 메모리만 정리
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
$ python3 util/cleanup.py --shm-only

출력:
======================================================================
LDM-EKI CLEANUP SCRIPT
======================================================================
Working directory: /home/jrpark/ldm-eki-release.v.beta

Items to be cleaned:
  - /dev/shm/ldm_eki_* (shared memory)

======================================================================
SCANNING...
======================================================================
shared memory: 8 files, 1.25 MB

Total: 8 files, 1.25 MB

======================================================================
Do you want to proceed? [y/N]: y

======================================================================
CLEANING...
======================================================================

Cleaning shared memory...
  ✓ Deleted: /dev/shm/ldm_eki_data (128.00 KB)
  ...
  ✓ Cleaned 8 shared memory files (1.25 MB)

======================================================================
SUMMARY
======================================================================
Deleted: 8 files (1.25 MB)
✓ Cleanup complete
======================================================================

사용 사례: 시뮬레이션 중단 후 공유 메모리만 정리할 때

예제 6: 이미 깨끗한 상태
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
$ python3 util/cleanup.py

출력:
======================================================================
LDM-EKI CLEANUP SCRIPT
======================================================================
Working directory: /home/jrpark/ldm-eki-release.v.beta

Items to be cleaned:
  - ./logs/
  - ./output/
  - /dev/shm/ldm_eki_* (shared memory)

======================================================================
SCANNING...
======================================================================

Total: 0 files, 0.00 B

✓ Nothing to clean - all directories are already empty
======================================================================

주의: 파일이 없으면 확인 프롬프트 없이 즉시 종료

예제 7: ldm-eki에서 자동 호출 (C++ 코드)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
C++ 코드 예시 (src/main_eki.cu):

    // Before simulation starts
    system("python3 util/cleanup.py");

    // User sees confirmation prompt
    // If user confirms, cleanup proceeds
    // Then simulation starts

이 방식의 장점:
    - 사용자가 직접 cleanup 실행할 필요 없음
    - 이전 데이터와 섞이는 것 방지
    - 공유 메모리 누수 방지

2.5 안전장치 메커니즘
================================================================================

안전장치 1: 확인 프롬프트
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
코드 위치: 262-267줄

    if not args.no_confirm and not args.dry_run:
        print("\n" + "=" * 70)
        response = input("Do you want to proceed? [y/N]: ").strip().lower()
        if response not in ['y', 'yes']:
            print("Aborted.")
            return 0

보호 대상: 실수로 중요한 데이터 삭제
작동 방식:
    - 기본값이 N (No) → 엔터만 쳐도 중단
    - y 또는 yes만 허용 (대소문자 무시)
    - 그 외 모든 입력은 중단

안전장치 2: Dry-run 모드
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
목적: 삭제 전 미리보기
특징:
    - 실제 파일은 건드리지 않음
    - 무엇이 삭제될지 정확히 보여줌
    - 확인 프롬프트도 건너뜀 (안전)

사용 사례:
    # 먼저 무엇이 삭제될지 확인
    python3 util/cleanup.py --dry-run

    # 결과 확인 후 실제 실행
    python3 util/cleanup.py

안전장치 3: 디렉토리 자체는 유지
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
코드 로직:
    - logs/ 디렉토리는 삭제 안 함
    - output/ 디렉토리는 삭제 안 함
    - 내용만 삭제

이유:
    - 시뮬레이션이 디렉토리 존재를 가정할 수 있음
    - 빈 디렉토리는 디스크 공간 차지 안 함
    - 디렉토리 재생성 로직 불필요

안전장치 4: 개별 파일 에러 처리
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
코드 위치: 128-142줄

    try:
        for item in os.listdir(path):
            item_path = os.path.join(path, item)
            try:
                # Delete item
            except Exception as e:
                print(f"  Warning: Failed to delete {item_path}: {e}")
    except Exception as e:
        print(f"  Error cleaning {path}: {e}")
        return 0, 0

보호 대상: 일부 파일 실패로 전체 정리 중단되는 것 방지
작동 방식:
    - 외부 try-except: 디렉토리 읽기 실패
    - 내부 try-except: 개별 파일 삭제 실패
    - 경고만 출력하고 계속 진행

예시 시나리오:
    - 파일 A: 삭제 성공
    - 파일 B: 권한 없음 → 경고 출력
    - 파일 C: 삭제 성공
    → 전체 작업은 성공으로 간주, B만 남음

안전장치 5: 권한 에러 처리
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
예외 처리:
    - PermissionError: 권한 없는 파일/디렉토리
    - FileNotFoundError: 이미 삭제된 파일 (무시)

공유 메모리 특수 처리:
    try:
        if os.path.exists('/dev/shm'):
            for entry in os.scandir('/dev/shm'):
                if entry.name.startswith('ldm_eki'):
                    shm_files.add(entry.path)
    except PermissionError:
        print("Warning: No permission to scan /dev/shm")

이유: 일부 시스템에서 /dev/shm 접근 제한될 수 있음

안전장치 6: 파일 존재 확인
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
코드 패턴:

    if os.path.exists(path):
        # Process

    # 또는

    try:
        # Process
    except FileNotFoundError:
        pass

이유:
    - 멀티 프로세스 환경에서 파일이 중간에 삭제될 수 있음
    - Python과 C++ 모두 공유 메모리 접근 가능

안전장치 7: 프로젝트 루트 고정
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
코드 위치: 38-41줄

    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    os.chdir(project_root)

보호 대상: 잘못된 디렉토리에서 실행되는 것 방지
작동 방식:
    - util/cleanup.py가 어디서 실행되든 프로젝트 루트로 이동
    - logs/, output/ 경로가 항상 올바르게 해석됨

예시:
    # 어디서 실행하든 동일하게 작동
    cd /tmp
    python3 /home/jrpark/ldm-eki-release.v.beta/util/cleanup.py

    # 내부적으로 /home/jrpark/ldm-eki-release.v.beta로 이동
    # 그 후 logs/, output/ 정리

안전장치 8: 스크립트 중단 처리
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
코드 위치: 310-318줄

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        print("\n\nAborted by user.")
        sys.exit(1)
    except Exception as e:
        print(f"\nError: {e}")
        sys.exit(1)

보호 대상: Ctrl+C 중단 시 깔끔한 종료
작동 방식:
    - KeyboardInterrupt: 사용자가 Ctrl+C 누름
    - Exception: 예상치 못한 에러
    - 둘 다 에러 메시지 출력 후 exit code 1로 종료

사용 사례:
    # 사용자가 삭제 진행 중 마음 바뀜
    $ python3 util/cleanup.py
    Do you want to proceed? [y/N]: y

    Cleaning logs/...
    ^C

    Aborted by user.

================================================================================
3. compare_all_receptors.py 완전 분석
================================================================================

3.1 스크립트 개요
================================================================================

파일 경로: /home/jrpark/ldm-eki-release.v.beta/util/compare_all_receptors.py
총 줄 수: 587줄
목적: 수용체별 관측 데이터 비교 및 방출량 추정 시각화
실행 시점: ldm-eki 종료 시 자동 호출
언어: Python 3
주요 의존성: numpy, matplotlib, struct

핵심 기능:
1. 16개 수용체 관측 데이터 시각화 (동적 확장 가능)
2. 입자 개수 및 선량 비교 (Single vs Ensemble)
3. EKI 방출량 추정 그래프
4. 다중 페이지 PDF 형식 출력 (3개 수용체/페이지)
5. 로그 파싱 및 공유 메모리 읽기

입력 파일:
- input/receptor.conf: 수용체 위치 정의
- input/eki.conf: EKI 설정 (time interval, true emissions)
- logs/ldm_eki_simulation.log: 시뮬레이션 로그 (파싱 대상)
- /dev/shm/ldm_eki_ensemble_obs_*: 앙상블 관측 데이터 (바이너리)
- logs/eki_iterations/*.npy: EKI 반복 결과 (NumPy 배열)

출력 파일:
- output/results/all_receptors_comparison.png (단일 페이지, ≤3 수용체)
- output/results/all_receptors_comparison_page*.png (다중 페이지, >3 수용체)

3.2 전체 코드 구조
================================================================================

[1-24줄] Docstring 및 Import
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
#!/usr/bin/env python3
"""
REAL comparison with all receptors shown separately
Dynamically generates multiple pages (3 receptors per page)
1. Particle counts for receptors
2. Observation dose for receptors
3. Emission estimates from EKI iterations (shown on all pages)

Dependencies:
    - numpy: Array operations
    - matplotlib: Plotting and visualization
    - struct: Binary data reading
    - re: Regular expression parsing
    - os, sys: File system operations

Input files required:
    - input/receptor.conf: Receptor configuration
    - input/eki.conf: EKI settings (timestep interval)
    - /dev/shm/ldm_eki_ensemble_observations_*: Observation data (binary)
    - logs/eki_iterations/*.pkl: Iteration results

Output:
    - output/results/all_receptors_comparison.png
"""
import numpy as np
import struct
import matplotlib.pyplot as plt
from matplotlib.gridspec import GridSpec
import re
import os

설명:
- struct: 바이너리 공유 메모리 파싱용
- re: 로그 파일 정규표현식 파싱용
- GridSpec: 복잡한 서브플롯 레이아웃용

[32-87줄] load_receptor_settings()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
목적: receptor.conf 파일 파싱
반환값: 딕셔너리 {'num_receptors': int, 'receptor_locations': [(lat, lon), ...]}

파싱 로직 상세 분석:

def load_receptor_settings(receptor_file='input/receptor.conf'):
    """Load receptor configuration from receptor.conf"""
    receptor_settings = {
        'num_receptors': 3,
        'receptor_locations': []
    }

    try:
        with open(receptor_file, 'r') as f:
            lines = f.readlines()
            in_receptor_locations = False

            for line in lines:
                line = line.strip()

                # Skip comments and empty lines
                if not line or line.startswith('#'):
                    continue

                # Normalize separator: convert ':' to '=' for uniform parsing
                if ':' in line and '=' not in line:
                    line = line.replace(':', '=', 1)

                # Parse number of receptors
                if 'NUM_RECEPTORS' in line:
                    receptor_settings['num_receptors'] = int(line.split('=')[1].strip())

                # Parse receptor locations
                elif 'RECEPTOR_LOCATIONS' in line:
                    in_receptor_locations = True
                    continue

                if in_receptor_locations:
                    # Stop if we hit another section
                    if '=' in line and not line.startswith('#'):
                        in_receptor_locations = False
                    # Parse location line
                    elif not line.startswith('#'):
                        try:
                            parts = line.split()
                            if len(parts) >= 2:
                                lat, lon = float(parts[0]), float(parts[1])
                                receptor_settings['receptor_locations'].append((lat, lon))
                        except:
                            pass

    except FileNotFoundError:
        print(f"Warning: Could not load receptor settings from {receptor_file}: File not found")
        print("Using default values")
        return None
    except Exception as e:
        print(f"Warning: Could not load receptor settings from {receptor_file}: {e}")
        print("Using default values")
        return None

    return receptor_settings

파싱 상태 머신:
    상태 1: 일반 라인 파싱
        - NUM_RECEPTORS: 값 추출
        - RECEPTOR_LOCATIONS: 상태 2로 전환

    상태 2: 수용체 위치 파싱 (in_receptor_locations=True)
        - 빈 라인: 무시
        - 주석: 무시
        - "lat lon" 형식: 파싱하여 리스트 추가
        - "KEY=" 형식: 상태 1로 복귀 (다음 섹션 시작)

예시 입력 파일 (receptor.conf):
    NUM_RECEPTORS: 16

    RECEPTOR_LOCATIONS:
    35.5 129.3
    35.5 129.4
    35.5 129.5
    ...
    35.8 129.6

파싱 결과:
    {
        'num_receptors': 16,
        'receptor_locations': [
            (35.5, 129.3),
            (35.5, 129.4),
            ...
        ]
    }

특수 처리:
    - 콜론과 등호 통합: "NUM_RECEPTORS: 16" → "NUM_RECEPTORS= 16"
    - 공백 허용: lat/lon 사이 공백 개수 무관
    - 에러 무시: 파싱 실패 라인은 건너뜀

[90-152줄] load_eki_settings()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
목적: eki.conf 파일 파싱 + receptor.conf 통합
반환값: 통합 설정 딕셔너리

def load_eki_settings(settings_file='input/eki.conf'):
    """Load EKI settings from configuration file"""
    settings = {
        'time_interval': 15.0,
        'num_receptors': 3,
        'receptor_locations': [],
        'num_timesteps': None  # Will be calculated from TRUE_EMISSION_SERIES
    }

    # Load receptor settings from separate file
    receptor_settings = load_receptor_settings()
    if receptor_settings:
        settings['num_receptors'] = receptor_settings['num_receptors']
        settings['receptor_locations'] = receptor_settings['receptor_locations']

    try:
        with open(settings_file, 'r') as f:
            lines = f.readlines()

            for i, line in enumerate(lines):
                line = line.strip()

                # Skip comments and empty lines
                if not line or line.startswith('#'):
                    continue

                # Normalize separator: convert ':' to '=' for uniform parsing
                if ':' in line and '=' not in line:
                    line = line.replace(':', '=', 1)

                # Parse time interval
                if 'EKI_TIME_INTERVAL' in line:
                    settings['time_interval'] = float(line.split('=')[1].strip())

        # Calculate number of timesteps from TRUE_EMISSION_SERIES length
        if settings['num_timesteps'] is None:
            # Count TRUE_EMISSION_SERIES entries
            true_emissions = load_true_emissions()
            if true_emissions is not None and len(true_emissions) > 0:
                settings['num_timesteps'] = len(true_emissions)
            else:
                # Fallback: try to read from setting.txt
                try:
                    with open('input/setting.txt', 'r') as f:
                        for line in f:
                            if 'Time_end' in line:
                                time_end_seconds = float(line.split(':')[1].strip())
                                settings['time_interval'] = int((time_end_seconds / 60) / settings['time_interval'])
                                break
                except:
                    settings['num_timesteps'] = 24  # Safe default

        print(f"[CONFIG] Loaded EKI settings from eki.conf and receptor.conf:")
        print(f"  - Time interval: {settings['time_interval']} minutes")
        print(f"  - Num timesteps: {settings['num_timesteps']}")
        print(f"  - Num receptors: {settings['num_receptors']} (from receptor.conf)")
        print(f"  - Receptor locations: {len(settings['receptor_locations'])} found (from receptor.conf)")

    except Exception as e:
        print(f"Warning: Could not load settings from {settings_file}: {e}")
        print("Using default values")

    return settings

통합 로직:
    1. receptor.conf 파싱 → 수용체 정보
    2. eki.conf 파싱 → 타임 인터벌
    3. TRUE_EMISSION_SERIES 길이로 타임스텝 수 계산
    4. Fallback: setting.txt의 Time_end 사용

타임스텝 계산 예시:
    - true_emissions 길이: 24
    → num_timesteps = 24

    또는

    - Time_end: 21600초 (6시간)
    - EKI_TIME_INTERVAL: 15분
    → num_timesteps = (21600 / 60) / 15 = 24

3.3 주요 함수 분석
================================================================================

함수 1: parse_single_particle_counts()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[154-186줄]

def parse_single_particle_counts(log_file='logs/ldm_eki_simulation.log', num_receptors=3):
    """Parse single mode particle counts - dynamic receptor support (default 3 for backward compatibility)"""
    observations = []

    try:
        with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                # Build dynamic regex pattern for all receptors
                # Pattern: [EKI_OBS] Observation X at t=Ys: R1=dose(count) R2=...
                if '[EKI_OBS]' in line and 'Observation' in line:
                    obs_entry = {'time_min': 0}

                    # Extract timestamp
                    time_match = re.search(r'at t=(\d+)s', line)
                    if time_match:
                        obs_entry['time_min'] = int(time_match.group(1)) / 60.0

                    # Extract all receptor data
                    for r in range(1, num_receptors + 1):
                        pattern = rf'R{r}=([\d.e+-]+)\((\d+)p\)'
                        match = re.search(pattern, line)
                        if match:
                            obs_entry[f'R{r}_dose'] = float(match.group(1))
                            obs_entry[f'R{r}_count'] = int(match.group(2))

                    if len(obs_entry) > 1:  # Has data beyond time
                        observations.append(obs_entry)

        print(f"Loaded {len(observations)} single mode observations with particle counts")
    except Exception as e:
        print(f"Error loading single particle counts: {e}")

    return observations

목적: 로그에서 초기 참값 시뮬레이션 관측값 추출
입력 로그 형식:
    [EKI_OBS] Observation 1 at t=900s: R1=1.23e-08(45p) R2=2.34e-09(12p) R3=0.00e+00(0p)

정규표현식 분석:
    1. 타임스탬프: r'at t=(\d+)s'
       - 매칭 예: "at t=900s"
       - 추출: 900 → 60.0으로 나눔 → 15.0분

    2. 수용체 데이터: rf'R{r}=([\d.e+-]+)\((\d+)p\)'
       - 매칭 예: "R1=1.23e-08(45p)"
       - 추출: dose=1.23e-08, count=45

반환 데이터 구조:
    [
        {
            'time_min': 15.0,
            'R1_dose': 1.23e-08,
            'R1_count': 45,
            'R2_dose': 2.34e-09,
            'R2_count': 12,
            ...
        },
        {
            'time_min': 30.0,
            ...
        }
    ]

동적 수용체 지원:
    - num_receptors 파라미터로 개수 제어
    - 루프로 R1, R2, ..., RN 모두 추출
    - 16개 수용체도 자동 지원

함수 2: parse_ensemble_particle_counts()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[188-240줄]

def parse_ensemble_particle_counts(log_file='logs/ldm_eki_simulation.log', num_receptors=3):
    """Parse ensemble particle counts from log - dynamic receptor support"""
    ensemble_data = {}

    try:
        with open(log_file, 'r', encoding='utf-8', errors='ignore') as f:
            for line in f:
                # Pattern: [EKI_ENSEMBLE_OBS] EnsX obsY: R1=... R2=...
                if '[EKI_ENSEMBLE_OBS]' in line:
                    # Try new format first: [EKI_ENSEMBLE_OBS] obsY at t=Xs: R1=countp R2=countp...
                    new_format_match = re.search(r'obs(\d+) at t=(\d+)s:', line)
                    if new_format_match:
                        obs_idx = int(new_format_match.group(1)) - 1  # Convert to 0-based

                        if obs_idx not in ensemble_data:
                            ensemble_data[obs_idx] = {}
                            for r in range(1, num_receptors + 1):
                                ensemble_data[obs_idx][f'R{r}_count'] = []

                        # Extract all receptor particle counts (already averaged in C++)
                        for r in range(1, num_receptors + 1):
                            pattern = rf'R{r}=(\d+)p'
                            match = re.search(pattern, line)
                            if match:
                                # Store as single-element array for compatibility with mean/std calculation
                                ensemble_data[obs_idx][f'R{r}_count'] = [int(match.group(1))]

                    else:
                        # Fallback to old format: [EKI_ENSEMBLE_OBS] EnsX obsY: R1=dose(count) R2=...
                        ens_match = re.search(r'Ens(\d+) obs(\d+):', line)
                        if ens_match:
                            ens_id = int(ens_match.group(1))
                            obs_idx = int(ens_match.group(2)) - 1  # Convert to 0-based

                            if obs_idx not in ensemble_data:
                                ensemble_data[obs_idx] = {}
                                for r in range(1, num_receptors + 1):
                                    ensemble_data[obs_idx][f'R{r}_dose'] = []
                                    ensemble_data[obs_idx][f'R{r}_count'] = []

                            # Extract all receptor data
                            for r in range(1, num_receptors + 1):
                                pattern = rf'R{r}=([\d.e+-]+)\((\d+)p\)'
                                match = re.search(pattern, line)
                                if match:
                                    ensemble_data[obs_idx][f'R{r}_dose'].append(float(match.group(1)))
                                    ensemble_data[obs_idx][f'R{r}_count'].append(int(match.group(2)))

        print(f"Loaded ensemble data for {len(ensemble_data)} observation points")
    except Exception as e:
        print(f"Error loading ensemble particle counts: {e}")

    return ensemble_data

목적: 앙상블 시뮬레이션 관측값 추출
데이터 구조:
    {
        0: {  # obs_idx (0-based)
            'R1_count': [45, 52, 38, ...],  # 각 앙상블 멤버의 카운트
            'R2_count': [12, 15, 9, ...],
            ...
        },
        1: {
            ...
        }
    }

두 가지 로그 형식 지원:
    1. 새 형식 (C++에서 이미 평균 계산):
       [EKI_ENSEMBLE_OBS] obs1 at t=900s: R1=45p R2=12p
       → 단일 값만 저장 (리스트에 1개 요소)

    2. 구 형식 (개별 앙상블 멤버):
       [EKI_ENSEMBLE_OBS] Ens1 obs1: R1=1.23e-08(45p) R2=...
       [EKI_ENSEMBLE_OBS] Ens2 obs1: R1=1.45e-08(52p) R2=...
       → 리스트에 누적

호환성 처리:
    - 새 형식 매칭 실패 시 자동으로 구 형식 시도
    - 두 형식 모두 동일한 데이터 구조로 변환
    - mean/std 계산 시 차이 없음

함수 3: load_ensemble_doses_from_shm()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[242-264줄]

def load_ensemble_doses_from_shm():
    """Load ensemble dose data from shared memory"""
    try:
        with open('/dev/shm/ldm_eki_ensemble_obs_config', 'rb') as f:
            config_data = f.read(12)
            num_ensembles, num_receptors, num_timesteps = struct.unpack('<iii', config_data)

        total_elements = num_ensembles * num_receptors * num_timesteps
        with open('/dev/shm/ldm_eki_ensemble_obs_data', 'rb') as f:
            flat_data = struct.unpack(f'<{total_elements}f', f.read(total_elements * 4))

        # After dimension fix, C++ sends data as [ensemble, timestep, receptor]
        observations = np.array(flat_data).reshape((num_ensembles, num_timesteps, num_receptors))

        # But visualization expects [ensemble, receptor, timestep], so transpose
        observations = np.transpose(observations, (0, 2, 1))  # Swap timestep and receptor dimensions

        print(f"Loaded ensemble doses: {num_ensembles} ensembles x {num_receptors} receptors x {num_timesteps} timesteps")
        print(f"  (transposed from timestep-major to receptor-major for visualization)")
        return observations
    except Exception as e:
        print(f"Error loading ensemble doses from shm: {e}")
        return None

목적: 공유 메모리에서 앙상블 선량 데이터 읽기 (바이너리)
공유 메모리 형식:
    1. Config 파일: /dev/shm/ldm_eki_ensemble_obs_config (12 bytes)
       - 4 bytes: num_ensembles (int32)
       - 4 bytes: num_receptors (int32)
       - 4 bytes: num_timesteps (int32)
       - Byte order: little-endian ('<iii')

    2. Data 파일: /dev/shm/ldm_eki_ensemble_obs_data (float32 배열)
       - 총 크기: num_ensembles × num_receptors × num_timesteps × 4 bytes
       - Byte order: little-endian ('<f')

struct.unpack() 사용법:
    - '<iii': little-endian, 3개 int32
    - f'<{total_elements}f': little-endian, N개 float32
    - 동적으로 요소 개수 계산

배열 재배열 로직:
    C++ 송신 형식: [ensemble][timestep][receptor]
    Python 수신 형식: (num_ensembles, num_timesteps, num_receptors)
    시각화 필요 형식: (num_ensembles, num_receptors, num_timesteps)

    해결: np.transpose(observations, (0, 2, 1))
          - axis 0 (ensemble): 그대로
          - axis 1 (timestep) ↔ axis 2 (receptor): 교환

왜 재배열 필요?
    - C++는 timestep-major (시간 순서대로 데이터 기록)
    - 시각화는 receptor-major (수용체별로 플롯)
    - Transpose하면 데이터 복사 없이 뷰만 변경 (효율적)

함수 4: load_eki_iterations()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[266-281줄]

def load_eki_iterations():
    """Load EKI iteration data for emission estimates"""
    iterations = []
    iteration_dir = 'logs/eki_iterations'

    if os.path.exists(iteration_dir):
        files = sorted([f for f in os.listdir(iteration_dir) if f.startswith('iteration_') and f.endswith('.npy')])
        for file in files:
            try:
                data = np.load(os.path.join(iteration_dir, file))
                iterations.append(data)
            except:
                pass
        print(f"Loaded {len(iterations)} EKI iterations")

    return iterations

목적: EKI 반복 결과 로드 (방출량 추정치)
파일 구조:
    logs/eki_iterations/
    ├── iteration_1.npy
    ├── iteration_2.npy
    └── iteration_N.npy

데이터 형식:
    각 .npy 파일은 2D NumPy 배열:
    - shape: (num_timesteps, num_ensemble)
    - 의미: 각 타임스텝별, 각 앙상블 멤버의 방출량 추정치

반환값:
    [
        array([[1.2e8, 1.3e8, ...], [1.1e8, 1.4e8, ...], ...]),  # iteration 1
        array([[1.5e8, 1.4e8, ...], [1.6e8, 1.5e8, ...], ...]),  # iteration 2
        ...
    ]

에러 처리:
    - 개별 파일 로드 실패 시 건너뜀 (pass)
    - 전체 로드는 계속 진행

함수 5: load_true_emissions()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[283-308줄]

def load_true_emissions():
    """Load true emission profile from eki.conf"""
    emissions = []
    try:
        with open('input/eki.conf', 'r') as f:
            in_section = False
            for line in f:
                # Support both ':' and '=' separators
                if 'TRUE_EMISSION_SERIES' in line and (':' in line or '=' in line):
                    in_section = True
                    continue
                if in_section:
                    line = line.strip()
                    # Stop at next section (key=value or key: value)
                    if not line or '=' in line or ':' in line:
                        if emissions:
                            break
                    else:
                        try:
                            emissions.append(float(line))
                        except ValueError:
                            pass
    except:
        pass

    return np.array(emissions) if emissions else None

목적: 참값 방출량 시계열 로드
입력 파일 형식 (eki.conf):
    TRUE_EMISSION_SERIES:
    1.5e8
    1.5e8
    1.5e8
    ...

파싱 상태 머신:
    상태 1: TRUE_EMISSION_SERIES 찾기
    상태 2: 숫자 라인 파싱 (in_section=True)
        - 빈 라인 또는 다음 섹션 만나면 종료

반환값:
    np.array([1.5e8, 1.5e8, 1.5e8, ...])
    또는
    None (파일 없거나 파싱 실패 시)

에러 허용:
    - ValueError: 숫자 아닌 라인 건너뜀
    - 예외: None 반환 (플롯에서 처리)

3.4 플롯 생성 로직
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━

함수: plot_emission_estimates()
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[310-374줄]

def plot_emission_estimates(ax, eki_iterations, true_emissions, num_timesteps, time_interval):
    """Plot emission estimates on given axis"""

    # Plot true emissions
    if true_emissions is not None and len(true_emissions) > 0:
        total_duration_minutes = num_timesteps * time_interval
        emission_times = np.linspace(0, total_duration_minutes, len(true_emissions))
        ax.plot(emission_times, true_emissions, 'k-', linewidth=3,
                label='True Emissions', alpha=0.9)

    # Plot EKI iteration estimates if available
    if eki_iterations:
        num_iters = len(eki_iterations)

        # Determine how many iterations to show (smart strategy)
        if num_iters == 1:
            iters_to_show = [0]
            show_labels = ['Iteration 1']
        elif num_iters <= 5:
            iters_to_show = list(range(num_iters))
            show_labels = [f'Iteration {i+1}' for i in range(num_iters)]
        else:
            iters_to_show = [0] + list(range(num_iters-3, num_iters))
            show_labels = ['Iteration 1'] + [f'Iteration {i+1}' for i in range(num_iters-3, num_iters)]

        # Generate colors dynamically
        colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(iters_to_show)))

        for color_idx, iter_idx in enumerate(iters_to_show):
            iteration = eki_iterations[iter_idx]
            if len(iteration) > 0 and iteration.ndim == 2:
                mean_est = iteration.mean(axis=1)
                std_est = iteration.std(axis=1)

                total_duration_minutes = num_timesteps * time_interval
                iter_times = np.linspace(0, total_duration_minutes, len(mean_est))

                linestyle = '-' if iter_idx == num_iters - 1 else '--'
                linewidth = 3 if iter_idx == num_iters - 1 else 2
                alpha = 0.9 if iter_idx == num_iters - 1 else 0.6

                ax.plot(iter_times, mean_est, linestyle, color=colors[color_idx],
                        linewidth=linewidth, label=show_labels[color_idx], alpha=alpha)

                # Show uncertainty only for last iteration
                if iter_idx == num_iters - 1:
                    ax.fill_between(iter_times,
                                   np.maximum(mean_est - std_est, 0),
                                   mean_est + std_est,
                                   color=colors[color_idx], alpha=0.15)
    else:
        ax.text(0.5, 0.5, 'No EKI iteration data available',
                transform=ax.transAxes, ha='center', va='center',
                fontsize=14, color='red')

    ax.axhline(y=1.5e8, color='blue', linestyle=':', linewidth=2,
               alpha=0.5, label='Prior Estimate')

    ax.set_xlabel('Time (minutes)', fontsize=12)
    ax.set_ylabel('Emission Rate (Bq)', fontsize=12)
    ax.set_title('EMISSION ESTIMATES (Linear Scale)', fontsize=13, fontweight='bold')
    ax.legend(loc='upper right', fontsize=10)
    ax.grid(True, alpha=0.3, which='both')
    ax.ticklabel_format(axis='y', style='scientific', scilimits=(0,0))

목적: 방출량 추정 그래프 생성
플롯 요소:
    1. 참값 (True Emissions): 검은색 실선
    2. EKI 추정값: 빨간색 계열 (밝음 → 진함)
    3. Prior 추정값: 파란색 점선 (1.5e8 Bq)
    4. 불확실성: 마지막 반복만 표시 (fill_between)

스마트 반복 선택 로직:
    반복 1개: [0] → "Iteration 1"
    반복 5개 이하: [0, 1, 2, 3, 4] → 전부 표시
    반복 6개 이상: [0, N-3, N-2, N-1] → 첫 반복 + 마지막 3개

    예시 (10개 반복):
        [0, 7, 8, 9] → "Iteration 1", "Iteration 8", "Iteration 9", "Iteration 10"

왜 선택적 표시?
    - 반복이 너무 많으면 그래프가 복잡해짐
    - 첫 반복: 초기 상태
    - 마지막 3개: 수렴 과정

색상 동적 생성:
    colors = plt.cm.Reds(np.linspace(0.3, 0.9, len(iters_to_show)))

    - Reds 컬러맵 사용
    - 0.3 ~ 0.9 범위 (너무 밝거나 어두운 색 제외)
    - 반복 진행할수록 진해짐

선 스타일:
    - 중간 반복: 점선 (--), 얇음 (linewidth=2), 반투명 (alpha=0.6)
    - 마지막 반복: 실선 (-), 굵음 (linewidth=3), 불투명 (alpha=0.9)

불확실성 밴드:
    ax.fill_between(iter_times,
                   np.maximum(mean_est - std_est, 0),  # 하한 (0 이상)
                   mean_est + std_est,                 # 상한
                   color=colors[color_idx], alpha=0.15)

    - 마지막 반복만 표시 (if iter_idx == num_iters - 1)
    - np.maximum(mean - std, 0): 음수 방지
    - alpha=0.15: 매우 연한 색 (가독성)

Y축 형식:
    ax.ticklabel_format(axis='y', style='scientific', scilimits=(0,0))

    - 과학적 표기법 강제 (1.5e8)
    - scilimits=(0,0): 항상 지수 사용

함수: create_receptor_comparison() (메인 함수)
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[375-580줄] - 매우 긴 함수, 핵심 로직만 발췌

def create_receptor_comparison():
    """Create comparison showing all receptors separately - generates multiple pages for > 3 receptors"""

    # Load settings and data
    eki_settings = load_eki_settings()
    num_receptors = eki_settings['num_receptors']
    num_timesteps = eki_settings['num_timesteps']
    time_interval = eki_settings['time_interval']

    num_pages = (num_receptors + 2) // 3  # Ceiling division
    print(f"\n📊 Generating plots for {num_receptors} receptors (from receptor.conf)")
    print(f"   Will create {num_pages} page(s) (3 receptors per page)")

    # Load all data
    single_data = parse_single_particle_counts(num_receptors=num_receptors)
    ensemble_particle_data = parse_ensemble_particle_counts(num_receptors=num_receptors)
    ensemble_doses = load_ensemble_doses_from_shm()
    eki_iterations = load_eki_iterations()
    true_emissions = load_true_emissions()

    # Prepare data arrays
    times = np.arange(1, num_timesteps + 1) * time_interval
    single_counts = [np.zeros(num_timesteps) for _ in range(num_receptors)]
    single_doses = [np.zeros(num_timesteps) for _ in range(num_receptors)]

    # Fill single mode data
    # ... (데이터 채우기 로직)

    # Process ensemble data
    # ... (앙상블 데이터 처리)

    # Generate multiple pages
    output_paths = []

    for page_idx in range(num_pages):
        start_receptor = page_idx * 3
        end_receptor = min(start_receptor + 3, num_receptors)
        receptors_on_page = list(range(start_receptor, end_receptor))
        num_cols = len(receptors_on_page)

        # Create figure with 3 rows
        fig = plt.figure(figsize=(6*num_cols, 14))
        gs = GridSpec(3, num_cols, figure=fig, hspace=0.3, wspace=0.3)

        # ROW 1: PARTICLE COUNTS
        for col, r in enumerate(receptors_on_page):
            ax = fig.add_subplot(gs[0, col])
            ax.plot(times, single_counts[r], 'o-', color=single_color, ...)
            ax.plot(times, ens_counts_mean[r], 's--', color=ensemble_color, ...)
            ax.fill_between(times, ..., color=ensemble_color, alpha=0.2)

        # ROW 2: OBSERVATION DOSES
        for col, r in enumerate(receptors_on_page):
            ax = fig.add_subplot(gs[1, col])
            ax.plot(times, single_doses[r], 'o-', color=single_color, ...)
            ax.plot(times, ens_dose_mean[r], 's--', color=ensemble_color, ...)
            ax.set_yscale('log')

        # ROW 3: EMISSION ESTIMATES (full width)
        ax_emission = fig.add_subplot(gs[2, :])
        plot_emission_estimates(ax_emission, eki_iterations, true_emissions, num_timesteps, time_interval)

        # Save figure
        if num_pages == 1:
            output_path = 'output/results/all_receptors_comparison.png'
        else:
            output_path = f'output/results/all_receptors_comparison_page{page_idx+1}.png'

        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        output_paths.append(output_path)
        print(f"   ✅ Saved: {output_path}")

        plt.close(fig)

    # Print summary
    # ... (통계 출력)

페이지 분할 로직:
    num_pages = (num_receptors + 2) // 3

    계산 예시:
        - 3 receptors: (3 + 2) // 3 = 1 page
        - 16 receptors: (16 + 2) // 3 = 6 pages

    페이지별 수용체 배분:
        Page 1: R1, R2, R3
        Page 2: R4, R5, R6
        ...
        Page 6: R16 (1개만)

GridSpec 레이아웃:
    3행 × num_cols열 (num_cols = 1~3)

    예시 (3개 수용체 페이지):
        ┌────────┬────────┬────────┐
        │  R1    │  R2    │  R3    │  ← 행 0: 입자 개수
        │ 입자   │ 입자   │ 입자   │
        ├────────┼────────┼────────┤
        │  R1    │  R2    │  R3    │  ← 행 1: 선량
        │ 선량   │ 선량   │ 선량   │
        ├────────┴────────┴────────┤
        │    방출량 추정           │  ← 행 2: 전체 폭
        │  (Emission Estimates)   │
        └─────────────────────────┘

파일명 규칙:
    - 1 페이지: all_receptors_comparison.png
    - 다중 페이지: all_receptors_comparison_page1.png, ..., page6.png

색상 코드:
    single_color = '#2E86C1'    # 파란색 (Single mode)
    ensemble_color = '#E74C3C'  # 빨간색 (Ensemble mode)

마커 스타일:
    - Single: 'o-' (원형 마커 + 실선)
    - Ensemble: 's--' (사각형 마커 + 점선)

Figure 크기:
    figsize=(6*num_cols, 14)

    - 1개 수용체: 6×14 inches
    - 2개 수용체: 12×14 inches
    - 3개 수용체: 18×14 inches

DPI 설정:
    plt.savefig(output_path, dpi=150, bbox_inches='tight')

    - dpi=150: 고해상도 (기본 100보다 50% 향상)
    - bbox_inches='tight': 여백 최소화

3.5 사용 예제 및 출력물
================================================================================

실행 방법:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
$ cd /home/jrpark/ldm-eki-release.v.beta
$ python3 util/compare_all_receptors.py

자동 실행 (ldm-eki 종료 시):
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
C++ 코드 (src/main_eki.cu):

    // After simulation completes
    system("python3 util/compare_all_receptors.py");

터미널 출력 예시:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
[CONFIG] Loaded EKI settings from eki.conf and receptor.conf:
  - Time interval: 15.0 minutes
  - Num timesteps: 24
  - Num receptors: 16 (from receptor.conf)
  - Receptor locations: 16 found (from receptor.conf)

======================================================================
ALL RECEPTORS COMPARISON - REAL DATA
======================================================================

📊 Generating plots for 16 receptors (from receptor.conf)
   Will create 6 page(s) (3 receptors per page)

Loaded 24 single mode observations with particle counts
Loaded ensemble data for 24 observation points
Ensemble particle data points from log: 24
Logged observation indices: [0, 1, 2, ..., 23]
Total logged observations: 24 out of 24
Loaded ensemble doses: 100 ensembles x 16 receptors x 24 timesteps
  (transposed from timestep-major to receptor-major for visualization)
Loaded 5 EKI iterations

🖼️  Generating page 1/6: R1-R3
   ✅ Saved: output/results/all_receptors_comparison_page1.png

🖼️  Generating page 2/6: R4-R6
   ✅ Saved: output/results/all_receptors_comparison_page2.png

🖼️  Generating page 3/6: R7-R9
   ✅ Saved: output/results/all_receptors_comparison_page3.png

🖼️  Generating page 4/6: R10-R12
   ✅ Saved: output/results/all_receptors_comparison_page4.png

🖼️  Generating page 5/6: R13-R15
   ✅ Saved: output/results/all_receptors_comparison_page5.png

🖼️  Generating page 6/6: R16
   ✅ Saved: output/results/all_receptors_comparison_page6.png

======================================================================
DATA SUMMARY
======================================================================
Single Mode Particle Totals: R1=1234, R2=567, R3=890, ...
Ensemble Mean Particle Totals: R1=1189, R2=543, R3=912, ...
Single Mode Peak Doses: R1=1.23e-08, R2=5.67e-09, R3=8.90e-09, ... Sv
Ensemble Mean Peak Doses: R1=1.19e-08, R2=5.43e-09, R3=9.12e-09, ... Sv
EKI Iterations Available: 5

📄 Total pages generated: 6
   • output/results/all_receptors_comparison_page1.png
   • output/results/all_receptors_comparison_page2.png
   • output/results/all_receptors_comparison_page3.png
   • output/results/all_receptors_comparison_page4.png
   • output/results/all_receptors_comparison_page5.png
   • output/results/all_receptors_comparison_page6.png
======================================================================

출력 파일 구조:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
output/results/
├── all_receptors_comparison_page1.png (247 KB)
├── all_receptors_comparison_page2.png (239 KB)
├── all_receptors_comparison_page3.png (318 KB)
├── all_receptors_comparison_page4.png (367 KB)
├── all_receptors_comparison_page5.png (239 KB)
└── all_receptors_comparison_page6.png (177 KB, 1개 수용체만)

플롯 내용 해석:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
1행: 입자 개수 (Particle Count)
    - X축: 시간 (분)
    - Y축: 입자 개수 (선형)
    - 파란색 원형: Single mode (참값)
    - 빨간색 사각형: Ensemble mean
    - 빨간색 밴드: ±1 표준편차

    해석:
        - Single과 Ensemble이 얼마나 일치하는가?
        - 불확실성 밴드가 참값을 포함하는가?

2행: 관측 선량 (Observation Dose)
    - X축: 시간 (분)
    - Y축: 선량 (Sv, 로그 스케일)
    - 같은 색상 코드

    해석:
        - 로그 스케일: 여러 자릿수 차이 시각화
        - 피크 시간 및 크기 비교

3행: 방출량 추정 (Emission Estimates)
    - X축: 시간 (분)
    - Y축: 방출률 (Bq, 선형)
    - 검은색 실선: 참값
    - 빨간색 계열: EKI 추정 (밝음 → 진함)
    - 파란색 점선: Prior (1.5e8 Bq)

    해석:
        - EKI가 참값에 수렴하는가?
        - 최종 추정값의 불확실성은?

데이터 품질 지표:
━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━
1. Single vs Ensemble 입자 개수 비교
    - 차이가 크면: 앙상블 크기 부족 또는 알고리즘 문제
    - 차이가 작으면: 통계적으로 안정적

2. 불확실성 밴드
    - 너무 넓으면: 앙상블 분산 큼, localization 필요
    - 너무 좁으면: 과적합 위험

3. 방출량 추정 수렴
    - 참값에 가까워지면: EKI 성공
    - 발산하면: 파라미터 조정 필요

================================================================================
Part 1 종료 - 계속 Part 2에서...
================================================================================

Part 1 요약:
- cleanup.py: 전체 코드 분석 완료 (319줄)
- compare_all_receptors.py: 전체 코드 분석 완료 (587줄)
- 총 분석 줄 수: 약 900줄 코드 + 문서화
- 실제 문서 길이: 약 1,050줄

Part 2 예고:
- detailed_postprocess.py 완전 분석
- visualize_vtk.py 완전 분석
- 사용 예제 및 통합 가이드

Part 3 예고:
- C++ VTK 출력 모듈 (ldm_plot_vtk.cu/cuh)
- Memory Doctor 시스템 (C++ + Python)
- Kernel Error Collector
- EKI Debug Logger
- 전체 도구 통합 워크플로우
